<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1"/>
  <title>Edge AI — Memristor Edge Learning & Energy-Efficient Attention — Curated Roundup</title>
  <style>
    body {
      font-family: system-ui, -apple-system, "Segoe UI", Roboto, "Helvetica Neue", Arial;
      line-height: 1.6;
      color: #111;
      padding: 28px;
      max-width: 900px;
      margin: auto;
      background: #fafafa;
    }
    h1 {
      font-size: 2rem;
      margin-bottom: 0.4rem;
      color: #0b63a8;
    }
    h2 {
      font-size: 1.25rem;
      margin-top: 1.5rem;
      color: #0b63a8;
    }
    .paper {
      margin: 12px 0;
      padding: 10px 12px;
      border-left: 4px solid #0b63a8;
      background: #f7fbff;
      border-radius: 6px;
    }
    .meta {
      font-size: 0.95rem;
      font-weight: 600;
      color: #0b63a8;
    }
    .desc {
      margin-top: 6px;
      font-size: 0.95rem;
      color: #333;
    }
    a {
      color: #0b63a8;
      text-decoration: none;
    }
    a:hover {
      text-decoration: underline;
    }
    ul {
      margin: 8px 0 12px 20px;
    }
    code {
      background: #eee;
      padding: 2px 6px;
      border-radius: 4px;
      font-size: 0.95em;
    }
    footer {
      margin-top: 30px;
      font-size: 0.85rem;
      color: #555;
      border-top: 1px solid #ddd;
      padding-top: 10px;
    }
  </style>
</head>
<body>

<h1>Edge AI — Memristor Edge Learning & Energy-Efficient Attention — a Curated Roundup</h1>

<p>
  This page summarizes key research directions in <strong>Edge Computing</strong>, 
  <strong>Neuro-Inspired Memristor Edge Learning</strong>, and 
  <strong>Energy-Efficient Attention Mechanisms</strong>. 
  Each section lists representative publications with short descriptions — 
  a quick reference for exploring energy-aware and hardware-integrated AI systems.
</p>

<hr/>

<h2>Edge Computing & Edge AI — Surveys and Foundations</h2>

<div class="paper">
  <div class="meta"><a href="https://arxiv.org/abs/2403.02619">Training Machine Learning Models at the Edge: A Survey</a> — arXiv</div>
  <div class="desc">A broad overview of edge-side learning and continual adaptation, covering communication, hardware, and optimization trade-offs for training directly on devices.</div>
</div>

<div class="paper">
  <div class="meta"><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC8780479/">Federated Learning in Edge Computing: A Systematic Survey</a> — Sensors Journal</div>
  <div class="desc">Examines federated learning frameworks designed for bandwidth-limited edge networks, emphasizing privacy, synchronization, and decentralized optimization.</div>
</div>

<div class="paper">
  <div class="meta"><a href="https://arxiv.org/html/2510.01439v1">Edge Artificial Intelligence: A Systematic Review</a> — arXiv</div>
  <div class="desc">Classifies edge AI systems by hardware type, data locality, and workload, offering an up-to-date taxonomy of architectures for embedded and real-time AI.</div>
</div>

<hr/>

<h2>Edge Learning with Fully Integrated Neuro-Inspired Memristor Chips</h2>

<div class="paper">
  <div class="meta"><a href="https://www.science.org/doi/10.1126/science.ade3483">Edge Learning Using a Fully Integrated Neuro-Inspired Memristor Chip</a> — Science</div>
  <div class="desc">Demonstrates a neuromorphic memristor chip capable of on-chip learning and inference. Combines analog crossbar computation and adaptive weight storage for ultra-low-power training directly at the edge.</div>
</div>

<div class="paper">
  <div class="meta"><a href="https://link.springer.com/article/10.1007/s40820-024-01368-7">A Fully-Integrated Memristor Chip for Edge Learning</a> — Springer</div>
  <div class="desc">Describes the circuit and materials design of a memristor array optimized for learning tasks, integrating local update rules and low-voltage synaptic operations.</div>
</div>

<div class="paper">
  <div class="meta"><a href="https://arxiv.org/pdf/2408.14680.pdf">On-Chip Learning with Memristor-Based Neural Networks</a> — arXiv</div>
  <div class="desc">Explores algorithms that tolerate device variability and noise in memristor arrays, enabling stable local learning and efficient analog weight updates.</div>
</div>

<hr/>

<h2>Energy-Efficient Attention for Edge AI</h2>

<div class="paper">
  <div class="meta"><a href="https://arxiv.org/abs/2209.09004">EcoFormer: Energy-Saving Attention with Linear Complexity</a> — NeurIPS / arXiv</div>
  <div class="desc">Introduces an energy-optimized attention mechanism using binary hashing and kernel approximations to achieve linear complexity and lower compute cost without large accuracy loss.</div>
</div>

<div class="paper">
  <div class="meta"><a href="https://arxiv.org/abs/2307.03493">ITA: An Energy-Efficient Attention and Softmax Accelerator</a> — arXiv</div>
  <div class="desc">Presents a hardware design for streaming integer attention computations, reducing memory access and improving inference latency on low-power devices.</div>
</div>

<div class="paper">
  <div class="meta"><a href="https://juser.fz-juelich.de/record/1038046/files/2409.19315v2.pdf">Analog In-Memory Attention Architectures for Low-Energy AI</a> — Preprint</div>
  <div class="desc">Describes analog in-memory implementations of transformer attention that minimize off-chip data movement and exploit resistive memory arrays for energy-proportional compute.</div>
</div>

<div class="paper">
  <div class="meta"><a href="https://dl.acm.org/doi/fullHtml/10.1145/3530811">Efficient Transformers: A Survey</a> — ACM</div>
  <div class="desc">Summarizes efficient transformer architectures — including sparse, low-rank, and kernelized attention — providing key context for lightweight attention in embedded systems.</div>
</div>

<hr/>

<h2>Cross-Layer and System Co-Design References</h2>

<div class="paper">
  <div class="meta"><a href="https://www.researchgate.net/publication/382679690_Energy-Efficient_AI_on_the_Edge">Energy-Efficient AI on the Edge</a> — Springer (Book Chapter)</div>
  <div class="desc">Discusses practical techniques like model pruning, quantization, and adaptive runtime scheduling for optimizing AI deployments on microcontrollers and edge NPUs.</div>
</div>

<div class="paper">
  <div class="meta"><a href="https://dl.acm.org/doi/full/10.1145/3589766">Energy-Efficient Approximate Edge Inference Systems</a> — ACM</div>
  <div class="desc">Analyzes system-level design choices for approximate computing and dynamic precision scaling to achieve energy–latency trade-offs in real-world embedded AI.</div>
</div>

<hr/>

<h2>Quick Takeaways</h2>
<ul>
  <li><strong>Edge AI is holistic:</strong> success depends on joint hardware, algorithm, and system-level design.</li>
  <li><strong>Memristor-based chips:</strong> enable truly local, analog learning — paving the way for self-adaptive edge nodes.</li>
  <li><strong>Efficient attention:</strong> EcoFormer and related methods show large energy savings through structured or approximate attention.</li>
  <li><strong>Co-design wins:</strong> aligning algorithmic sparsity and memory layout with analog or low-bit accelerators maximizes energy efficiency.</li>
  <li><strong>Practical edge AI:</strong> combines digital accelerators with neuromorphic and in-memory hardware for domain-specific workloads.</li>
</ul>

</body>
</html>
